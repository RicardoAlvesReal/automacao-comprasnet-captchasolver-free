#!/usr/bin/env python3
"""
üéØ SISTEMA DE DOWNLOAD AUTOM√ÅTICO DE LICITA√á√ïES 2023-2025
=========================================================
Download autom√°tico de todas as licita√ß√µes do ComprasNet de 2023 at√© agora
com resolu√ß√£o de CAPTCHA usando sistema heur√≠stico 98%+
"""

import asyncio
import logging
import time
import random
import os
import json
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from playwright.async_api import async_playwright
from urllib.parse import urlencode

# Importar sistema de CAPTCHA otimizado
from comprasnet_download_monitor_open import ComprasNetDownloadMonitor
from heuristica_analisador import AnalisadorInteligente
from heuristica_reconhecedor import ReconhecedorAdaptativo
from captcha_resolver_v2_clean import CaptchaResolverV2

def convert_numpy_types(obj):
    """Converte tipos numpy para tipos serializ√°veis em JSON"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

# Configurar logging
logging.basicConfig(level=logging.INFO, format='üìÖ [%(asctime)s] %(levelname)s: %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)

class ComprasNetDownloadAutomatico:
    def __init__(self):
        # Inicializar progresso primeiro (para evitar erros)
        self.progresso = None
        self.log_progresso = Path("progresso_downloads.json")
        
        # Configura√ß√µes de download - DEVE SER ANTES de inicializar navegador
        self.downloads_dir = Path("downloads_licitacoes")
        self.downloads_dir.mkdir(exist_ok=True)
        
        # Configura√ß√µes do navegador
        self.page = None
        self.browser = None
        
        # Base URL do ComprasNet para consulta de licita√ß√µes
        self.base_url = "https://comprasnet.gov.br/ConsultaLicitacoes/ConsLicitacao_Filtro.asp"
        
        # Sistema de resolu√ß√£o de CAPTCHA otimizado
        self.captcha_resolver = ComprasNetDownloadMonitor()
        
        # Sistema heur√≠stico otimizado (98%+ sucesso)
        # Removido na limpeza: self.analisador_heuristico = AnalisadorInteligente()
        
        # Vari√°veis para controle de CAPTCHA e ML
        self.ultimo_captcha_resolvido = None
        
        # Sistema de reconhecimento heur√≠stico como backup
        self.reconhecedor_heuristico = ReconhecedorAdaptativo()
        logger.info("üß† Reconhecedor heur√≠stico integrado como backup")
        
        # üíæ Controle de CAPTCHA para treinamento ML
        self.ultimo_captcha_resolvido = None
        logger.info("üéØ Sistema de confirma√ß√£o de CAPTCHA para ML inicializado")
        
        # Carregar configura√ß√£o otimizada
        self.config = self.carregar_config_otimizada()
        
        # Inicializar progresso agora que todas as vari√°veis est√£o configuradas
        self.progresso = self.inicializar_progresso_limpo()
        
        logger.info("üéØ Sistema de Download Autom√°tico inicializado com heur√≠stica 98%+")
        logger.info(f"üìÅ Downloads ser√£o salvos em: {self.downloads_dir}")
        logger.info("üîÑ MODO: Sempre come√ßar do zero (progresso anterior ignorado)")
        
    def carregar_config_otimizada(self):
        """Carrega a configura√ß√£o otimizada do sistema heur√≠stico"""
        try:
            with open("config_otimizado_98.json", 'r', encoding='utf-8') as f:
                config = json.load(f)
                logger.info("‚úÖ Configura√ß√£o heur√≠stica otimizada carregada (meta 98%)")
                return config
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao carregar config otimizada: {e}")
            return {
                "meta_confianca_98": True,
                "thresholds_otimizados": {
                    "texto_preto_threshold": 25,
                    "texto_preto_confianca": 0.95
                },
                "metodos_prioritarios": [
                    "binarizacao_texto_preto",
                    "treinamento_manual",
                    "easyocr_otimizado"
                ]
            }
        
    def inicializar_progresso_limpo(self):
        """Sempre inicializa um progresso limpo, ignorando arquivos anteriores"""
        logger.info("üÜï Inicializando progresso limpo - come√ßando do zero")
        
        # Remover arquivo de progresso anterior se existir
        if hasattr(self, 'log_progresso') and self.log_progresso.exists():
            try:
                self.log_progresso.unlink()
                logger.info("üóëÔ∏è Arquivo de progresso anterior removido")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao remover progresso anterior: {e}")
        
        # Retornar progresso limpo
        return {
            "periodos_concluidos": [], 
            "ultimo_download": None,
            "downloads_realizados": 0,
            "data_inicio_processamento": datetime.now().isoformat()
        }
        
    def carregar_progresso(self):
        """M√©todo auxiliar para carregar progresso (n√£o usado no modo 'sempre do zero')"""
        if self.log_progresso.exists():
            try:
                with open(self.log_progresso, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao carregar progresso: {e}")
                return {"periodos_concluidos": [], "ultimo_download": None}
        return {"periodos_concluidos": [], "ultimo_download": None}
    
    def salvar_progresso(self):
        """Salva progresso atual"""
        try:
            # Verificar se progresso existe
            if not hasattr(self, 'progresso') or self.progresso is None:
                logger.warning("‚ö†Ô∏è Progresso n√£o inicializado, pulando salvamento")
                return
                
            # Converter tipos numpy antes de salvar
            progresso_convertido = convert_numpy_types(self.progresso)
            
            with open(self.log_progresso, 'w', encoding='utf-8') as f:
                json.dump(progresso_convertido, f, indent=2, default=str)
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar progresso: {e}")
    
    def gerar_periodos_quinzenais(self, data_inicio, data_fim):
        """
        Gera per√≠odos de 15 dias entre as datas especificadas
        O ComprasNet s√≥ aceita per√≠odos m√°ximos de 15 dias
        """
        periodos = []
        data_atual = data_inicio
        
        while data_atual <= data_fim:
            # Calcular fim do per√≠odo (m√°ximo 15 dias)
            fim_periodo = min(data_atual + timedelta(days=14), data_fim)
            
            periodo = {
                "inicio": data_atual.strftime("%d/%m/%Y"),
                "fim": fim_periodo.strftime("%d/%m/%Y"),
                "inicio_obj": data_atual,
                "fim_obj": fim_periodo
            }
            
            periodos.append(periodo)
            
            # Pr√≥ximo per√≠odo come√ßa no dia seguinte
            data_atual = fim_periodo + timedelta(days=1)
        
        return periodos
    
    def construir_url_consulta(self, data_inicio, data_fim):
        """
        Constr√≥i URL de consulta baseada no padr√£o fornecido
        """
        # Par√¢metros baseados no link fornecido
        parametros = {
            'numprp': '',  # N√∫mero da proposta (vazio para todas)
            'dt_publ_ini': data_inicio,  # Data in√≠cio
            'dt_publ_fim': data_fim,     # Data fim
            'chkModalidade': '1,2,3,20,5,99',  # Modalidades
            'chk_concor': '31,32,41,42,49',    # Concorr√™ncias
            'chk_pregao': '1,2,3,4',           # Preg√µes
            'chk_rdc': '1,2,3,4',              # RDC
            'optTpPesqMat': 'C',               # Tipo pesquisa material
            'optTpPesqServ': 'S',              # Tipo pesquisa servi√ßo
            'chkTodos': '-1',                  # Todos
            'chk_concorTodos': '-1',           # Todas concorr√™ncias
            'chk_pregaoTodos': '-1',           # Todos preg√µes
            'txtlstUf': 'ES',                  # Estado: Esp√≠rito Santo
            'txtlstMunicipio': '57053',        # Munic√≠pio
            'txtlstUasg': '925968',            # UASG
            'txtlstGrpMaterial': '70',         # Grupo material
            'txtlstClasMaterial': '',          # Classifica√ß√£o material
            'txtlstMaterial': '',              # Material
            'txtlstGrpServico': '',            # Grupo servi√ßo
            'txtlstServico': '',               # Servi√ßo
            'txtObjeto': ''                    # Objeto
        }
        
        # Construir URL completa
        url_completa = f"{self.base_url}?{urlencode(parametros)}"
        return url_completa
    
    async def inicializar_navegador(self):
        """Inicializa o navegador Playwright usando Chromium persistente n√£o-an√¥nimo"""
        try:
            self.playwright = await async_playwright().start()
            
            # Criar pasta de dados do usu√°rio tempor√°ria para contexto persistente
            user_data_dir = Path.cwd() / "temp_user_data"
            user_data_dir.mkdir(exist_ok=True)
            
            logger.info("üöÄ Inicializando Chromium persistente para downloads n√£o-an√¥nimos...")
            
            # Usar launch_persistent_context para garantir modo n√£o-an√¥nimo
            self.context = await self.playwright.chromium.launch_persistent_context(
                user_data_dir=str(user_data_dir),
                headless=False,  # SEMPRE vis√≠vel
                proxy={
                    "server": "http://filtroweb.tjes.jus.br:9090"
                },
                args=[
                    '--disable-blink-features=AutomationControlled',
                    '--disable-web-security',
                    '--disable-features=VizDisplayCompositor',
                    '--disable-download-protection',
                    '--disable-popup-blocking',
                    '--allow-running-insecure-content',
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-background-networking',
                    '--disable-background-timer-throttling',
                    '--disable-backgrounding-occluded-windows',
                    '--disable-renderer-backgrounding',
                    '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                ],
                accept_downloads=True,
                downloads_path=str(self.downloads_dir),
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                bypass_csp=True,
                ignore_https_errors=True,
                extra_http_headers={
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                    'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Cache-Control': 'max-age=0'
                }
            )
            
            # Obter a primeira p√°gina do contexto persistente
            self.page = self.context.pages[0] if self.context.pages else await self.context.new_page()
            
            logger.info("‚úÖ Contexto persistente n√£o-an√¥nimo inicializado")
            
            # Configurar eventos de download ANTES de qualquer navega√ß√£o
            self.page.on("download", self.handle_download)
            logger.info("üì• Manipulador de downloads configurado")
            
            # Aguardar um pouco para garantir que tudo est√° configurado
            await asyncio.sleep(1)
            
            logger.info("üåê Navegador Chromium inicializado com downloads otimizados")
            logger.info("üîí Modo n√£o-an√¥nimo ativado para downloads corretos")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar navegador: {e}")
            return False
    
    def analisar_arquivo_download(self, nome_arquivo):
        """Analisa e categoriza o arquivo de download"""
        if not nome_arquivo:
            return {
                "tipo": "DESCONHECIDO",
                "categoria": "Arquivo sem nome",
                "numerico": False,
                "valido": False
            }
        
        nome_lower = nome_arquivo.lower()
        nome_sem_extensao = nome_arquivo
        
        # Detectar ZIP
        if nome_lower.endswith('.zip'):
            nome_sem_extensao = nome_arquivo[:-4]  # Remove .zip
            
            # Verificar se √© num√©rico
            if nome_sem_extensao.isdigit():
                return {
                    "tipo": "ZIP",
                    "categoria": "ZIP num√©rico (licita√ß√£o)",
                    "numerico": True,
                    "valido": True,
                    "codigo_licitacao": nome_sem_extensao
                }
            else:
                return {
                    "tipo": "ZIP",
                    "categoria": "ZIP nomeado",
                    "numerico": False,
                    "valido": True
                }
        
        # Outros tipos de arquivo
        extensoes_conhecidas = ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.txt', '.rtf']
        for ext in extensoes_conhecidas:
            if nome_lower.endswith(ext):
                return {
                    "tipo": ext.upper().replace('.', ''),
                    "categoria": f"Documento {ext.upper()}",
                    "numerico": False,
                    "valido": True
                }
        
        return {
            "tipo": "OUTRO",
            "categoria": "Arquivo n√£o categorizado",
            "numerico": False,
            "valido": True
        }

    def extrair_info_licitacao(self):
        """Extrai informa√ß√µes da licita√ß√£o da URL atual para criar nome inteligente"""
        try:
            if hasattr(self, 'page') and self.page:
                url_atual = self.page.url
                logger.info(f"üîç Extraindo info da URL: {url_atual}")
                
                # Extrair par√¢metros da URL
                info = {
                    "coduasg": "925968",  # UASG padr√£o
                    "numprp": "UNKNOWN",
                    "modprp": "UNKNOWN"
                }
                
                # Buscar padr√µes na URL
                import re
                
                # Padr√£o para coduasg
                match_uasg = re.search(r'coduasg=(\d+)', url_atual)
                if match_uasg:
                    info["coduasg"] = match_uasg.group(1)
                
                # Padr√£o para numprp
                match_numprp = re.search(r'numprp=(\d+)', url_atual)
                if match_numprp:
                    info["numprp"] = match_numprp.group(1)
                
                # Padr√£o para modprp
                match_modprp = re.search(r'modprp=(\d+)', url_atual)
                if match_modprp:
                    info["modprp"] = match_modprp.group(1)
                
                logger.info(f"üìã Info extra√≠da: UASG={info['coduasg']}, NumProp={info['numprp']}, ModProp={info['modprp']}")
                return info
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair info da licita√ß√£o: {e}")
        
        # Valores padr√£o em caso de erro
        return {
            "coduasg": "925968",
            "numprp": "UNKNOWN", 
            "modprp": "UNKNOWN"
        }

    async def handle_download(self, download):
        """Manipula downloads autom√°ticos com controle de fluxo e renomea√ß√£o inteligente"""
        try:
            # Obter nome original do arquivo (normalmente UUID)
            nome_original = download.suggested_filename or "arquivo_sem_nome.zip"
            
            # Extrair informa√ß√µes da licita√ß√£o para criar nome inteligente
            info_licitacao = self.extrair_info_licitacao()
            
            # Detectar se o nome √© UUID e precisa ser renomeado
            import re
            padrao_uuid = r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'
            eh_uuid = re.match(padrao_uuid, nome_original.replace('.zip', ''), re.IGNORECASE)
            
            if eh_uuid:
                # üéØ RENOMEA√á√ÉO INTELIGENTE: UUID ‚Üí Nome Significativo
                nome_inteligente = f"{info_licitacao['coduasg']}_{info_licitacao['modprp']}_{info_licitacao['numprp']}.zip"
                logger.info(f"üîÑ RENOMEANDO UUID para nome inteligente:")
                logger.info(f"   üìõ UUID Original: {nome_original}")
                logger.info(f"   üéØ Nome Inteligente: {nome_inteligente}")
                nome_para_salvar = nome_inteligente
            else:
                # Manter nome original se n√£o for UUID
                nome_para_salvar = nome_original
                logger.info(f"üì¶ Arquivo com nome v√°lido: {nome_original}")
            
            # Analisar o arquivo (agora com nome inteligente)
            analise = self.analisar_arquivo_download(nome_para_salvar)
            
            # Log espec√≠fico baseado na an√°lise
            if analise["numerico"] and analise["tipo"] == "ZIP":
                logger.info(f"üì¶ {analise['categoria']} detectado: {nome_original}")
                logger.info(f"üî¢ C√≥digo da licita√ß√£o: {analise.get('codigo_licitacao', 'N/A')}")
            else:
                logger.info(f"ÔøΩ {analise['categoria']} detectado: {nome_original}")
            
            # üéØ CRIAR NOME INTELIGENTE baseado no contexto da licita√ß√£o
            if eh_uuid:
                # Usar nome inteligente para UUIDs
                nome_arquivo = f"licitacao_{info_licitacao['coduasg']}_{info_licitacao['modprp']}_{info_licitacao['numprp']}.zip"
                logger.info(f"üîÑ RENOMEA√á√ÉO APLICADA:")
                logger.info(f"   üìõ UUID Original: {nome_original}")
                logger.info(f"   üéØ Nome Inteligente: {nome_arquivo}")
            else:
                # Criar nome √∫nico com timestamp para nomes n√£o-UUID
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                nome_arquivo = f"licitacao_{timestamp}_{nome_original}"
                logger.info(f"üì¶ Nome v√°lido mantido: {nome_arquivo}")
            
            caminho_arquivo = self.downloads_dir / nome_arquivo
            
            # Salvar o download
            await download.save_as(caminho_arquivo)
            
            logger.info(f"‚úÖ Download salvo: {nome_arquivo}")
            logger.info(f"üìÅ Arquivo original: {nome_original}")
            logger.info(f"üìç Localiza√ß√£o: {caminho_arquivo}")
            
            # üéØ REGISTRAR SUCESSO E CONTROLAR FLUXO
            sucesso_info = {
                "arquivo": nome_arquivo,
                "arquivo_original": nome_original,
                "timestamp": timestamp,
                "tamanho": caminho_arquivo.stat().st_size if caminho_arquivo.exists() else 0,
                "url_origem": self.page.url if hasattr(self, 'page') else 'N/A',
                "analise_arquivo": analise,
                "tipo_arquivo": analise["tipo"],
                "categoria": analise["categoria"],
                "nome_numerico": analise["numerico"],
                "codigo_licitacao": analise.get("codigo_licitacao", "N/A"),
                "status": "sucesso"
            }
            
            # Atualizar progresso
            if hasattr(self, 'progresso') and self.progresso is not None:
                # Registrar download bem-sucedido
                if "downloads_sucesso" not in self.progresso:
                    self.progresso["downloads_sucesso"] = []
                
                self.progresso["downloads_sucesso"].append(sucesso_info)
                self.progresso["ultimo_download"] = sucesso_info
                self.progresso["total_downloads_realizados"] = len(self.progresso["downloads_sucesso"])
                
                # Marcar como deve pular para pr√≥xima licita√ß√£o
                self.progresso["continuar_proxima_licitacao"] = True
                
                self.salvar_progresso()
                
                # üìÑ GERAR LOG DETALHADO DE SUCESSO
                self.gerar_log_sucesso(sucesso_info)
                
                # Mensagem espec√≠fica baseada na an√°lise
                analise = sucesso_info.get('analise_arquivo', {})
                if analise.get('numerico') and analise.get('codigo_licitacao'):
                    logger.info(f"üéâ SUCESSO! {analise['categoria']} baixado: {analise['codigo_licitacao']}.zip - Total: {self.progresso['total_downloads_realizados']}")
                else:
                    logger.info(f"üéâ SUCESSO! {analise.get('categoria', 'Arquivo')} baixado - Total: {self.progresso['total_downloads_realizados']}")
                    
                logger.info("‚û°Ô∏è Sistema continuar√° automaticamente para pr√≥xima licita√ß√£o...")
            
            # ‚úÖ CONFIRMAR SUCESSO DEFINITIVO DO DOWNLOAD
            self.ultimo_download_sucesso = True
            logger.info("üéØ DOWNLOAD CONFIRMADO E PROCESSADO COM SUCESSO!")
            
            # üéØ CONFIRMAR CAPTCHA COMO SUCESSO PARA TREINAMENTO ML
            await self.confirmar_captcha_sucesso_para_ml()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar download: {e}")
            self.ultimo_download_sucesso = False
            return False
    
    def gerar_log_sucesso(self, sucesso_info):
        """Gera log detalhado de download bem-sucedido"""
        try:
            # Caminho do arquivo de log de sucessos
            log_sucessos = self.downloads_dir / "downloads_sucessos.log"
            
            # Informa√ß√µes para o log
            timestamp = datetime.now().strftime('%d/%m/%Y %H:%M:%S')
            
            # Detalhes espec√≠ficos baseados na an√°lise
            analise = sucesso_info.get('analise_arquivo', {})
            detalhes_arquivo = f"ÔøΩ {analise.get('categoria', 'Arquivo')}: {sucesso_info.get('arquivo_original', 'N/A')}"
            
            # Informa√ß√µes extras para licita√ß√µes num√©ricas
            info_extra = ""
            if analise.get('numerico') and analise.get('codigo_licitacao'):
                info_extra = f"ÔøΩ C√≥digo da licita√ß√£o: {analise['codigo_licitacao']}\n"
            
            log_entry = f"""
[{timestamp}] ‚úÖ DOWNLOAD BEM-SUCEDIDO
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìÅ Arquivo salvo: {sucesso_info['arquivo']}
{detalhes_arquivo}
{info_extra}‚è∞ Timestamp: {sucesso_info['timestamp']}
üì¶ Tamanho: {sucesso_info['tamanho']} bytes
üåê URL de origem: {sucesso_info['url_origem']}
üìä Status: {sucesso_info['status']}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

"""
            
            # Escrever no arquivo de log
            with open(log_sucessos, "a", encoding="utf-8") as f:
                f.write(log_entry)
                
            logger.info(f"üìù Log de sucesso gravado em: {log_sucessos}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao gerar log de sucesso: {e}")
    
    async def navegar_para_periodo(self, periodo):
        """Navega para p√°gina de consulta de um per√≠odo espec√≠fico"""
        try:
            url = self.construir_url_consulta(periodo["inicio"], periodo["fim"])
            
            logger.info(f"üîç Consultando per√≠odo: {periodo['inicio']} a {periodo['fim']}")
            logger.info(f"üåê URL: {url}")
            
            await self.page.goto(url, wait_until='domcontentloaded', timeout=15000)
            
            # Aguardar carregamento da p√°gina (otimizado)
            await asyncio.sleep(0.5)
            
            # NOVO: Verificar e clicar no bot√£o OK se presente
            logger.info("üîç Verificando se h√° bot√£o OK para clicar...")
            try:
                botao_ok = await self.page.query_selector('input[value="OK"]')
                
                if botao_ok:
                    logger.info("‚úÖ Bot√£o OK encontrado - clicando para abrir resultados...")
                    await botao_ok.click()
                    
                    # Aguardar navega√ß√£o para p√°gina de resultados (otimizado)
                    await self.page.wait_for_load_state('domcontentloaded', timeout=8000)
                    await asyncio.sleep(0.5)
                    
                    nova_url = self.page.url
                    logger.info(f"üìç Navegou para p√°gina de resultados: {nova_url}")
                    
                    if "ConsLicitacao_Relacao.asp" in nova_url:
                        logger.info("‚úÖ P√°gina de resultados carregada com sucesso")
                    else:
                        logger.warning(f"‚ö†Ô∏è URL inesperada ap√≥s clique no OK: {nova_url}")
                else:
                    logger.info("üìã Bot√£o OK n√£o encontrado - p√°gina j√° pode estar nos resultados")
                    
            except Exception as ok_error:
                logger.warning(f"‚ö†Ô∏è Erro ao tratar bot√£o OK: {ok_error}")
                # Continuar mesmo se houver erro com o bot√£o OK
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao navegar para per√≠odo: {e}")
            return False
    
    async def processar_licitacoes_periodo(self, periodo):
        """Processa todas as licita√ß√µes de um per√≠odo - adaptado para ASP cl√°ssico"""
        try:
            # Aguardar carregamento completo
            await self.page.wait_for_load_state('networkidle')
            await asyncio.sleep(2)
            
            # Buscar pelos bot√µes "Itens e Download" espec√≠ficos
            logger.info("üîç Procurando bot√µes 'Itens e Download'...")
            
            # Usar o seletor correto descoberto
            botoes_itens = await self.page.query_selector_all('input[value="Itens e Download"]')
            
            if not botoes_itens:
                # Fallback para outros seletores
                logger.info("üîÑ Tentando seletores alternativos...")
                seletores_alternativos = [
                    'input[value*="Itens"]',
                    'input[name="itens"]',
                    'a[href*="Itens"]',
                    'input[onclick*="VisualizarItens"]'
                ]
                
                for seletor in seletores_alternativos:
                    botoes_itens = await self.page.query_selector_all(seletor)
                    if botoes_itens:
                        logger.info(f"‚úÖ {len(botoes_itens)} bot√£o(√µes) encontrado(s) com: {seletor}")
                        break
            else:
                logger.info(f"‚úÖ {len(botoes_itens)} bot√£o(√µes) 'Itens e Download' encontrado(s)")

            if not botoes_itens:
                logger.warning(f"‚ö†Ô∏è Nenhum bot√£o de itens encontrado no per√≠odo {periodo['inicio']} a {periodo['fim']}")
                return 0

            logger.info(f"üìã Processando {len(botoes_itens)} licita√ß√£o(√µes) no per√≠odo")
            
            downloads_realizados = 0
            licitacoes_processadas = 0
            
            # üîÑ PROCESSAR LICITA√á√ïES UMA POR VEZ, VOLTANDO SEMPRE PARA A LISTAGEM
            while licitacoes_processadas < len(botoes_itens):
                try:
                    licitacoes_processadas += 1
                    logger.info(f"üìÑ Processando licita√ß√£o {licitacoes_processadas}/{len(botoes_itens)}")
                    
                    # üîÑ SEMPRE RE-BUSCAR OS BOT√ïES NA P√ÅGINA ATUAL
                    logger.info("üîç Re-buscando bot√µes 'Itens e Download' na p√°gina atual...")
                    botoes_atuais = await self.page.query_selector_all('input[value="Itens e Download"]')
                    
                    if not botoes_atuais:
                        logger.warning("‚ö†Ô∏è Nenhum bot√£o encontrado na p√°gina atual")
                        break
                    
                    if licitacoes_processadas > len(botoes_atuais):
                        logger.info("‚úÖ Todas as licita√ß√µes desta p√°gina foram processadas")
                        break
                    
                    # Pegar o primeiro bot√£o dispon√≠vel (sempre o primeiro n√£o processado)
                    botao_item = botoes_atuais[0]
                    
                    # Obter informa√ß√µes do bot√£o antes de clicar
                    try:
                        value = await botao_item.get_attribute('value')
                        onclick = await botao_item.get_attribute('onclick')
                        logger.info(f"ÔøΩ Clicando no bot√£o: {value}")
                        if onclick:
                            logger.info(f"üîó Onclick: {onclick}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erro ao obter atributos do bot√£o: {e}")
                    
                    # Clicar no bot√£o "Itens e Download"
                    await botao_item.click()
                    
                    # Aguardar carregamento da nova p√°gina
                    logger.info("‚è≥ Aguardando p√°gina de detalhes...")
                    try:
                        # Aguardar mudan√ßa de URL para p√°gina de download
                        await self.page.wait_for_url("**/download/download_editais_detalhe.asp*", timeout=15000)
                        logger.info("‚úÖ P√°gina de detalhes carregada")
                        
                        current_url = self.page.url
                        logger.info(f"üìç URL atual: {current_url}")
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Timeout ao aguardar p√°gina de detalhes: {e}")
                        # Continuar mesmo assim (otimizado)
                        await self.page.wait_for_load_state('domcontentloaded', timeout=5000)
                        await asyncio.sleep(0.5)
                        current_url = self.page.url
                        logger.info(f"üìç URL atual: {current_url}")
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Timeout ao aguardar p√°gina: {e}")
                        continue

                    # Procurar bot√£o de download na p√°gina ASP
                    logger.info("üîΩ Procurando bot√£o de download...")
                    
                    # No ASP cl√°ssico, os bot√µes podem ter v√°rias formas
                    botao_download = None
                    
                    # Tentar diferentes seletores para bot√£o de download
                    seletores_download = [
                        'input[name="Download"]',
                        'input[value="Download"]', 
                        'input[value*="Download"]',
                        'a[href*="download"]',
                        'input[type="submit"][value*="Download"]',
                        'button[name*="download"]',
                        'input[onclick*="download"]'
                    ]
                    
                    for seletor in seletores_download:
                        botao_download = await self.page.query_selector(seletor)
                        if botao_download:
                            logger.info(f"‚úÖ Bot√£o de download encontrado com seletor: {seletor}")
                            break
                    
                    if botao_download:
                        logger.info("üì• Iniciando download...")
                        
                        try:
                            # Verificar se o bot√£o abre popup ou navega
                            onclick = await botao_download.get_attribute('onclick')
                            target = await botao_download.get_attribute('target')
                            
                            # Usar expect_popup() para detectar CAPTCHA diretamente
                            logger.info("üì• Bot√£o Download encontrado - usando expect_popup para capturar CAPTCHA...")
                            
                            async with self.page.context.expect_page() as popup_info:
                                logger.info("üîÑ Clique realizado - aguardando popup...")
                                await botao_download.click()
                                
                            popup_page = await popup_info.value
                            popup_url = popup_page.url
                            logger.info(f"üéâ POPUP CAPTCHA DETECTADO: {popup_url}")
                            
                            # Verificar se √© p√°gina de CAPTCHA
                            if "Download.asp" in popup_url:
                                logger.info("‚úÖ Confirmado: Popup √© p√°gina de CAPTCHA")
                                await asyncio.sleep(3)  # Aguardar carregamento completo
                                
                                # Inicializar flag de sucesso
                                self.ultimo_download_sucesso = False
                                
                                # üéØ PROCESSAR CAPTCHA COM CONTROLE INTELIGENTE
                                logger.info("üöÄ Iniciando processo de CAPTCHA com controle de fluxo...")
                                
                                # Usar loop personalizado com parada imediata em caso de sucesso
                                tentativas_captcha = 0
                                download_realizado = False
                                
                                while tentativas_captcha < 30 and not download_realizado:
                                    logger.info(f"üîÑ Tentativa {tentativas_captcha+1}/30 de CAPTCHA")
                                    
                                    # Resolver CAPTCHA com sistema V2.0 otimizado
                                    sucesso_captcha = await self.resolver_captcha_heuristico_otimizado(popup_page)
                                    
                                    if sucesso_captcha:
                                        logger.info("‚úÖ CAPTCHA resolvido e clicado!")
                                        
                                        # üéØ AGUARDAR CONFIRMA√á√ÉO REAL DO DOWNLOAD
                                        download_confirmado = False
                                        try:
                                            logger.info("‚è≥ Aguardando confirma√ß√£o de download do navegador...")
                                            
                                            # Verificar se popup redirecionou (otimizado)
                                            await asyncio.sleep(0.3)
                                            current_url = popup_page.url
                                            logger.info(f"üåê URL ap√≥s clique: {current_url}")
                                            
                                            # Verificar se h√° mensagens na p√°gina (otimizado)
                                            try:
                                                page_text = await popup_page.text_content("body", timeout=1500)
                                                if "erro" in page_text.lower() or "incorret" in page_text.lower():
                                                    logger.warning(f"‚ùå Erro detectado na p√°gina: {page_text[:200]}")
                                                    continue  # Tentar pr√≥ximo CAPTCHA
                                                elif "download" in page_text.lower() or "arquivo" in page_text.lower():
                                                    logger.info(f"üìÑ Resposta do servidor: {page_text[:200]}")
                                            except:
                                                pass
                                            
                                            # üö® AGUARDAR EVENTO REAL DE DOWNLOAD DO NAVEGADOR (otimizado)
                                            try:
                                                async with popup_page.expect_download(timeout=8000) as download_info:
                                                    pass  # Clique j√° foi feito, s√≥ aguardando confirma√ß√£o
                                                
                                                # ‚úÖ DOWNLOAD CONFIRMADO PELO NAVEGADOR!
                                                download = await download_info.value
                                                nome_arquivo = download.suggested_filename or "arquivo_sem_nome"
                                                download_confirmado = True
                                                
                                                logger.info(f"üéâ DOWNLOAD CONFIRMADO PELO NAVEGADOR: {nome_arquivo}")
                                                
                                                # Analisar arquivo para log espec√≠fico
                                                analise = self.analisar_arquivo_download(nome_arquivo)
                                                
                                                if analise["numerico"] and analise["tipo"] == "ZIP":
                                                    logger.info(f"üì¶ {analise['categoria']}: {analise.get('codigo_licitacao', nome_arquivo)}.zip")
                                                else:
                                                    logger.info(f"üì¶ {analise['categoria']}: {nome_arquivo}")
                                                
                                                # Processar download com renomea√ß√£o inteligente
                                                await self.handle_download(download)
                                                download_realizado = True
                                                
                                                logger.info("‚úÖ DOWNLOAD PROCESSADO! Continuando para pr√≥xima licita√ß√£o...")
                                                break  # Sair do loop de tentativas - SUCESSO CONFIRMADO!
                                                
                                            except Exception as download_error:
                                                logger.warning(f"‚ö†Ô∏è Download n√£o foi iniciado pelo navegador: {download_error}")
                                                download_confirmado = False
                                                # Continuar para pr√≥xima tentativa de CAPTCHA
                                            
                                        except Exception as e:
                                            logger.warning(f"‚ö†Ô∏è Erro na verifica√ß√£o de download: {e}")
                                            download_confirmado = False
                                    else:
                                        logger.warning(f"‚ö†Ô∏è CAPTCHA falhou na tentativa {tentativas_captcha+1}")
                                    
                                    # Verificar flag de sucesso global
                                    if hasattr(self, 'ultimo_download_sucesso') and self.ultimo_download_sucesso:
                                        logger.info("üéâ Sucesso detectado via flag! Parando...")
                                        download_realizado = True
                                        break
                                    
                                    # Recarregar apenas se necess√°rio
                                    if tentativas_captcha < 14 and not download_realizado:
                                        logger.info("ÔøΩ Recarregando para nova tentativa...")
                                        try:
                                            await popup_page.reload(wait_until="networkidle")
                                            await asyncio.sleep(2)
                                        except:
                                            pass
                                    
                                    tentativas_captcha += 1
                                
                                # Fechar popup ap√≥s processamento (sucesso ou falha)
                                await popup_page.close()
                                logger.info("üóÇÔ∏è Popup CAPTCHA fechado")
                                
                                # üéØ VERIFICAR RESULTADO FINAL - APENAS COM CONFIRMA√á√ÉO REAL
                                if download_realizado:
                                    downloads_realizados += 1
                                    logger.info(f"üéâ DOWNLOAD {licitacoes_processadas} CONFIRMADO PELO NAVEGADOR!")
                                    logger.info(f"üìä Total de downloads confirmados: {downloads_realizados}")
                                    
                                    # ‚úÖ SUCESSO CONFIRMADO - Voltar para listagem e continuar
                                    logger.info("‚û°Ô∏è Download confirmado! Voltando para listagem...")
                                    
                                else:
                                    logger.warning(f"‚ùå DOWNLOAD {licitacoes_processadas} N√ÉO CONFIRMADO ap√≥s {tentativas_captcha} tentativas de CAPTCHA")
                                    logger.info("‚û°Ô∏è Sem confirma√ß√£o de download - Voltando para listagem...")
                                
                            else:
                                # Se n√£o for CAPTCHA, fechar popup e continuar
                                logger.warning(f"‚ö†Ô∏è Popup n√£o √© CAPTCHA: {popup_url}")
                                await popup_page.close()
                                
                        except Exception as e:
                            logger.error(f"‚ùå Erro ao processar download: {e}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Bot√£o de download n√£o encontrado para licita√ß√£o {licitacoes_processadas}")
                    
                    # üîô SEMPRE VOLTAR PARA A P√ÅGINA DE LISTAGEM AP√ìS CADA LICITA√á√ÉO
                    logger.info("üîô Voltando para p√°gina de listagem...")
                    try:
                        # Verificar se ainda estamos na p√°gina de detalhes
                        if 'download_editais_detalhe.asp' in self.page.url or 'Download.asp' in self.page.url:
                            await self.page.go_back()
                            await self.page.wait_for_load_state('domcontentloaded', timeout=10000)
                            await asyncio.sleep(1)
                        
                        # Verificar se voltamos para a listagem
                        if 'ConsLicitacao_Relacao.asp' not in self.page.url:
                            # Se go_back n√£o funcionou, navegar diretamente
                            url_listagem = self.page.url.replace('download_editais_detalhe.asp', '../ConsLicitacao_Relacao.asp')
                            if 'ConsLicitacao_Relacao.asp' not in url_listagem:
                                # Construir URL de listagem baseada no per√≠odo
                                url_listagem = "https://comprasnet.gov.br/ConsultaLicitacoes/ConsLicitacao_Relacao.asp"
                            
                            logger.info(f"üîÑ Navegando diretamente para: {url_listagem}")
                            await self.page.goto(url_listagem, wait_until='domcontentloaded', timeout=10000)
                            await asyncio.sleep(1)
                        
                        logger.info(f"‚úÖ De volta √† listagem: {self.page.url}")
                        
                    except Exception as nav_error:
                        logger.warning(f"‚ö†Ô∏è Erro ao voltar para listagem: {nav_error}")
                        # Se tudo falhar, reconstruir a consulta
                        try:
                            url_original = self.construir_url_consulta(periodo["inicio"], periodo["fim"])
                            await self.page.goto(url_original, wait_until='domcontentloaded')
                            await asyncio.sleep(2)
                            # Clicar no bot√£o OK para voltar aos resultados
                            botao_ok = await self.page.query_selector('input[value="OK"]')
                            if botao_ok:
                                await botao_ok.click()
                                await self.page.wait_for_load_state('domcontentloaded', timeout=10000)
                                await asyncio.sleep(2)
                        except Exception as rebuild_error:
                            logger.error(f"‚ùå Erro cr√≠tico ao reconstruir navega√ß√£o: {rebuild_error}")
                            break
                    
                except Exception as e:
                    logger.error(f"‚ùå Erro ao processar licita√ß√£o {licitacoes_processadas}: {e}")
                    # Tentar voltar para listagem mesmo em caso de erro
                    try:
                        if 'ConsLicitacao_Relacao.asp' not in self.page.url:
                            await self.page.go_back()
                            await self.page.wait_for_load_state('domcontentloaded', timeout=5000)
                    except:
                        pass
                    continue
            
            # Verificar se h√° pr√≥xima p√°gina (navega√ß√£o ASP)
            try:
                logger.info("üîç Verificando se h√° pr√≥xima p√°gina...")
                
                # No ASP, o bot√£o de pr√≥xima p√°gina pode ter diferentes formatos
                seletores_proxima = [
                    'input[value="Pr√≥xima"]',
                    'input[value="Pr√≥ximo"]', 
                    'input[value*="Pr√≥x"]',
                    'a[href*="proxima"]',
                    'a[href*="proximo"]',
                    'input[name*="next"]',
                    'input[onclick*="proxima"]'
                ]
                
                botao_proxima = None
                for seletor in seletores_proxima:
                    botao_proxima = await self.page.query_selector(seletor)
                    if botao_proxima:
                        logger.info(f"‚úÖ Bot√£o 'Pr√≥xima' encontrado: {seletor}")
                        break
                
                if botao_proxima:
                    logger.info("‚û°Ô∏è Navegando para pr√≥xima p√°gina...")
                    await botao_proxima.click()
                    await self.page.wait_for_load_state('networkidle')
                    await asyncio.sleep(2)
                    
                    # Processar pr√≥xima p√°gina recursivamente
                    downloads_proxima = await self.processar_licitacoes_periodo(periodo)
                    downloads_realizados += downloads_proxima
                else:
                    logger.info("üìÑ N√£o h√° pr√≥xima p√°gina dispon√≠vel")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao verificar pr√≥xima p√°gina: {e}")
            
            logger.info(f"‚úÖ Per√≠odo processado: {downloads_realizados} downloads realizados")
            return downloads_realizados
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar licita√ß√µes do per√≠odo: {e}")
            return 0
    
    async def processar_captcha_download(self, page, numero_licitacao):
        """Processa CAPTCHA e realiza download"""
        try:
            logger.info(f"üîí Procurando CAPTCHA na p√°gina...")
            
            # Aguardar poss√≠vel CAPTCHA aparecer
            await asyncio.sleep(2)
            
            # Tentar resolver CAPTCHA at√© 30 vezes
            tentativas_captcha = 0
            download = None
            
            while tentativas_captcha < 30 and not download:
                # Usar o sistema V2.0 otimizado para resolver o captcha
                sucesso_captcha = await self.resolver_captcha_heuristico_otimizado(page)
                
                if sucesso_captcha:
                    logger.info(f"‚úÖ Tentativa {tentativas_captcha+1}: CAPTCHA resolvido e bot√£o clicado automaticamente!")
                    try:
                        # Aguardar download ap√≥s clique autom√°tico
                        async with page.expect_download(timeout=10000) as download_info:
                            pass  # O clique j√° foi feito automaticamente na fun√ß√£o
                        download = await download_info.value
                        logger.info(f"üì• Download iniciado: {download.suggested_filename}")
                        await self.handle_download(download)
                        return True
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Download n√£o iniciou ap√≥s CAPTCHA: {e}")
                else:
                    logger.warning(f"‚ö†Ô∏è Falha ao resolver CAPTCHA na tentativa {tentativas_captcha+1}")
                
                if not download:
                    # Recarregar para nova tentativa
                    logger.info("ÔøΩ Recarregando para nova tentativa...")
                    await page.reload(wait_until="networkidle")
                    await asyncio.sleep(2)
                
                tentativas_captcha += 1
            
            if not download:
                logger.error(f"‚ùå Falha em todas as tentativas de CAPTCHA para licita√ß√£o {numero_licitacao}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar CAPTCHA: {e}")
            return False
    
    
    async def processar_captcha_com_monitor(self, nova_aba, numero_licitacao):
        """Usa o sistema heur√≠stico otimizado (98%+) para resolver CAPTCHA"""
        try:
            logger.info(f"ÔøΩ Iniciando resolu√ß√£o de CAPTCHA com heur√≠stica 98%+ para licita√ß√£o {numero_licitacao}")
            
            # Tentar resolver CAPTCHA at√© 3 vezes (reduzido devido √† alta precis√£o)
            tentativas_captcha = 0
            while tentativas_captcha < 30:
                logger.info(f"üéØ Tentativa {tentativas_captcha+1}/30 de resolu√ß√£o com heur√≠stica otimizada")
                
                # Usar o sistema heur√≠stico integrado
                botao_confirmar = await self.resolver_captcha_heuristico_otimizado(nova_aba)
                
                if botao_confirmar:
                    logger.info(f"‚úÖ CAPTCHA resolvido com heur√≠stica 98%+! Clicando para download...")
                    try:
                        async with nova_aba.expect_download(timeout=15000) as download_info:
                            await botao_confirmar.click()
                        download = await download_info.value
                        logger.info(f"üì• Download iniciado: {download.suggested_filename}")
                        await self.handle_download(download)
                        return True
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Download n√£o iniciou ap√≥s CAPTCHA: {e}")
                else:
                    logger.warning(f"‚ö†Ô∏è Falha ao resolver CAPTCHA na tentativa {tentativas_captcha+1}")
                
                # Recarregar para nova tentativa (menos necess√°rio com 98% de sucesso)
                if tentativas_captcha < 29:  # N√£o recarregar na √∫ltima tentativa (30-1)
                    logger.info("üîÑ Recarregando p√°gina para nova tentativa...")
                    await nova_aba.reload(wait_until="networkidle")
                    await asyncio.sleep(2)  # Tempo reduzido
                
                tentativas_captcha += 1
            
            logger.error(f"‚ùå Falha em todas as tentativas de CAPTCHA para licita√ß√£o {numero_licitacao}")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar CAPTCHA com heur√≠stica: {e}")
            return False
            
            # Aguardar carregamento completo da p√°gina
            await nova_aba.wait_for_load_state('networkidle')
            await asyncio.sleep(2)
            
            # Primeiro: tentar download direto pelo bot√£o Download
            logger.info("üîç Procurando bot√£o Download...")
            botao_download = await nova_aba.query_selector('input[name="Download"]')
            
            if botao_download:
                logger.info("ÔøΩ Bot√£o Download encontrado - tentando download direto...")
                
                # Tentar download direto at√© 3 vezes
                for tentativa in range(30):
                    try:
                        logger.info(f"üîÑ Tentativa {tentativa+1}/30 de download direto...")
                        
                        # Aguardar download
                        async with nova_aba.expect_download(timeout=15000) as download_info:
                            await botao_download.click()
                        
                        download = await download_info.value
                        logger.info(f"‚úÖ Download direto bem-sucedido: {download.suggested_filename}")
                        await self.handle_download(download)
                        return True
                        
                    except Exception as e:
                        logger.info(f"‚ö†Ô∏è Download direto falhou na tentativa {tentativa+1}: {e}")
                        await asyncio.sleep(2)
                
                # Se download direto falhou, verificar se apareceu CAPTCHA
                logger.info("üîí Download direto falhou - verificando se h√° CAPTCHA...")
                await asyncio.sleep(2)
                
                # Procurar por elementos CAPTCHA com prioridade ComprasNet
                seletores_captcha = [
                    'img[src*="captcha.aspx?opt=image"]',  # PRIORIT√ÅRIO: ComprasNet espec√≠fico
                    'img[src*="captcha.aspx"]',            # ComprasNet gen√©rico
                    'img[src*="captcha"]',
                    'img[alt*="captcha"]', 
                    'img[src*="security"]',
                    'input[name*="captcha"]',
                    'input[placeholder*="captcha"]',
                    'input[placeholder*="c√≥digo"]',
                    'canvas'
                ]
                
                captcha_encontrado = False
                for seletor in seletores_captcha:
                    elemento = await nova_aba.query_selector(seletor)
                    if elemento:
                        logger.info(f"üîí CAPTCHA encontrado com seletor: {seletor}")
                        captcha_encontrado = True
                        break
                
                if captcha_encontrado:
                    logger.info("ü§ñ Iniciando resolu√ß√£o autom√°tica de CAPTCHA...")
                    
                    # Usar o sistema V2.0 otimizado para resolver o captcha na nova aba
                    tentativas_captcha = 0
                    while tentativas_captcha < 30:
                        logger.info(f"üîÑ Tentativa {tentativas_captcha+1}/30 de resolu√ß√£o de CAPTCHA")
                        
                        sucesso_captcha = await self.resolver_captcha_heuristico_otimizado(nova_aba)
                        
                        if sucesso_captcha:
                            logger.info(f"‚úÖ CAPTCHA resolvido e bot√£o clicado automaticamente!")
                            try:
                                # Aguardar download ap√≥s clique autom√°tico
                                async with nova_aba.expect_download(timeout=15000) as download_info:
                                    pass  # O clique j√° foi feito automaticamente na fun√ß√£o
                                download = await download_info.value
                                logger.info(f"üì• Download iniciado: {download.suggested_filename}")
                                await self.handle_download(download)
                                return True
                                
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è Download n√£o iniciou ap√≥s CAPTCHA: {e}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Falha ao resolver CAPTCHA na tentativa {tentativas_captcha+1}")
                        
                        # Recarregar para nova tentativa
                        if tentativas_captcha < 29:  # N√£o recarregar na √∫ltima tentativa (30-1)
                            logger.info("üîÑ Recarregando p√°gina para nova tentativa...")
                            await nova_aba.reload(wait_until="networkidle")
                            await asyncio.sleep(3)
                        
                        tentativas_captcha += 1
                    
                    logger.error(f"‚ùå Falha em todas as tentativas de CAPTCHA para licita√ß√£o {numero_licitacao}")
                    return False
                    
                else:
                    # N√£o h√° CAPTCHA, mas download direto tamb√©m falhou
                    logger.warning("‚ö†Ô∏è Nenhum CAPTCHA encontrado e download direto falhou")
                    
                    # Tentar outros bot√µes poss√≠veis
                    logger.info("üîç Procurando bot√µes alternativos...")
                    botoes_alternativos = [
                        'input[type="submit"]',
                        'button[type="submit"]',
                        'input[value*="Baixar"]',
                        'input[value*="Confirmar"]',
                        'a[href*="download"]'
                    ]
                    
                    for seletor in botoes_alternativos:
                        botao_alt = await nova_aba.query_selector(seletor)
                        if botao_alt:
                            logger.info(f"üîÑ Tentando bot√£o alternativo: {seletor}")
                            try:
                                async with nova_aba.expect_download(timeout=10000) as download_info:
                                    await botao_alt.click()
                                download = await download_info.value
                                logger.info(f"üì• Download via bot√£o alternativo: {download.suggested_filename}")
                                await self.handle_download(download)
                                return True
                            except:
                                continue
                    
                    logger.error(f"‚ùå Nenhum m√©todo de download funcionou para licita√ß√£o {numero_licitacao}")
                    return False
            else:
                logger.warning("‚ö†Ô∏è Bot√£o Download n√£o encontrado na nova aba")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar download em nova aba: {e}")
            logger.error(f"üåê URL: {url_captcha}")
            return False
    
    async def resolver_captcha_heuristico_otimizado(self, page):
        """Resolve CAPTCHA usando sistema heur√≠stico otimizado + an√°lise por caractere"""
        try:
            logger.info("üß† Aplicando an√°lise heur√≠stica avan√ßada com segmenta√ß√£o por caractere...")
            
            # Aguardar a imagem do CAPTCHA aparecer
            await asyncio.sleep(2)
            
            # üì∏ CAPTURA MELHORADA: Fazer screenshot da p√°gina toda primeiro
            try:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                os.makedirs("debug_sistema/paginas_licitacao", exist_ok=True)
                screenshot_path = os.path.join("debug_sistema", "paginas_licitacao", f"captcha_page_{timestamp}.png")
                await page.screenshot(path=screenshot_path, full_page=True)
                logger.info(f"üì∏ Screenshot da p√°gina salva: {screenshot_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao salvar screenshot da p√°gina: {e}")
            
            # Procurar imagem do CAPTCHA com prioridade para ComprasNet
            img_captcha = None
            captcha_selectors = [
                'img[src*="captcha.aspx?opt=image"]',  # PRIORIT√ÅRIO: ComprasNet espec√≠fico
                'img[src*="captcha.aspx"]',            # ComprasNet gen√©rico
                'img[src*="captcha"]',
                'img[alt*="captcha"]', 
                'img[id*="captcha"]',
                'img[src*="security"]',
                'img[src*="verify"]',
                'canvas',
                'img[src*=".aspx"]'  # Para outros CAPTCHAs ASP.NET
            ]
            
            for selector in captcha_selectors:
                img_captcha = await page.query_selector(selector)
                if img_captcha:
                    logger.info(f"üîç CAPTCHA encontrado com seletor: {selector}")
                    break
            
            if not img_captcha:
                logger.warning("‚ö†Ô∏è Imagem do CAPTCHA n√£o encontrada")
                return False
            
            # üéØ MELHORAR CAPTURA: Primeiro tentar obter tamanho real da imagem
            try:
                # Obter propriedades da imagem
                img_props = await img_captcha.evaluate('''element => {
                    return {
                        src: element.src,
                        width: element.naturalWidth || element.width,
                        height: element.naturalHeight || element.height,
                        offsetWidth: element.offsetWidth,
                        offsetHeight: element.offsetHeight,
                        clientWidth: element.clientWidth,
                        clientHeight: element.clientHeight
                    };
                }''')
                
                logger.info(f"üìè Propriedades da imagem CAPTCHA: {img_props}")
                
                # Se a imagem √© muito pequena, tentar for√ßar um tamanho maior
                if img_props['width'] < 100 or img_props['height'] < 50:
                    logger.warning(f"‚ö†Ô∏è Imagem muito pequena ({img_props['width']}x{img_props['height']}), tentando redimensionar...")
                    
                    # Tentar for√ßar tamanho maior via CSS
                    await page.evaluate('''() => {
                        const captchaImg = document.querySelector('img[src*="captcha.aspx?opt=image"], img[src*="captcha.aspx"], img[src*="captcha"], img[alt*="captcha"], img[id*="captcha"]');
                        if (captchaImg) {
                            captchaImg.style.width = '200px';
                            captchaImg.style.height = '80px';
                            captchaImg.style.imageRendering = 'pixelated';
                            captchaImg.style.transform = 'scale(3)';
                            captchaImg.style.transformOrigin = 'top left';
                        }
                    }''')
                    
                    await asyncio.sleep(0.3)  # Aguardar aplica√ß√£o do CSS (otimizado)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao obter propriedades da imagem: {e}")
            
            # Capturar screenshot da imagem do CAPTCHA
            try:
                captcha_screenshot = await img_captcha.screenshot()
                logger.info(f"üì∏ Screenshot do CAPTCHA capturado: {len(captcha_screenshot)} bytes")
            except Exception as e:
                logger.error(f"‚ùå Erro ao capturar screenshot do CAPTCHA: {e}")
                return False
            
            # Salvar temporariamente para an√°lise
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                tmp_file.write(captcha_screenshot)
                caminho_temp = tmp_file.name
            
            # üéØ SISTEMA V2.0: Resolu√ß√£o avan√ßada com m√∫ltiplas estrat√©gias
            logger.info("üöÄ INICIANDO SISTEMA CAPTCHA V2.0 (6+ CARACTERES GARANTIDOS)")
            
            # Inicializar resolver V2.0 se n√£o existir
            if not hasattr(self, 'resolver_v2'):
                self.resolver_v2 = CaptchaResolverV2()
            
            # Carregar imagem para an√°lise V2.0
            import cv2
            img = cv2.imread(caminho_temp)
            
            # Tentar resolu√ß√£o V2.0 primeiro
            resultado_v2 = self.resolver_v2.resolver_captcha_completo(img, salvar_debug=True, salvar_sucesso=False)
            
            if resultado_v2.get('sucesso') and resultado_v2.get('tem_6_chars'):
                texto_resolvido = resultado_v2['texto']
                confianca = resultado_v2['confianca']
                metodo = resultado_v2['metodo']
                logger.info(f"ÔøΩ SISTEMA V2.0 SUCCESS: '{texto_resolvido}' ({metodo}, conf: {confianca:.2f}, chars: {len(texto_resolvido)})")
                
                # Inserir o texto no campo de CAPTCHA
                try:
                    # Procurar campo de entrada do CAPTCHA
                    campo_captcha = await page.query_selector('input[name*="captcha"]')
                    if not campo_captcha:
                        campo_captcha = await page.query_selector('input[id*="captcha"]')
                    if not campo_captcha:
                        campo_captcha = await page.query_selector('input[type="text"]')
                    
                    if campo_captcha:
                        await campo_captcha.fill(texto_resolvido)
                        logger.info(f"‚úÖ V2.0: Texto '{texto_resolvido}' inserido no campo CAPTCHA")
                        
                        # Procurar e clicar no bot√£o de confirma√ß√£o
                        try:
                            # M√©todo 1: Tentar clique JavaScript primeiro (evita sobreposi√ß√£o)
                            logger.info("üîÑ V2.0: Tentando clique JavaScript no bot√£o...")
                            sucesso_js = await page.evaluate('''() => {
                                // Procurar bot√£o de confirma√ß√£o
                                let botao = document.querySelector('input[type="submit"][value="Confirmar"]');
                                if (!botao) botao = document.querySelector('input[type="submit"]');
                                if (!botao) botao = document.querySelector('button[type="submit"]');
                                if (!botao) botao = document.querySelector('input[value*="Confirmar"]');
                                if (!botao) botao = document.querySelector('input[value*="OK"]');
                                
                                if (botao) {
                                    botao.focus();
                                    botao.click();
                                    return true;
                                }
                                return false;
                            }''')
                            
                            if sucesso_js:
                                logger.info("‚úÖ V2.0: Bot√£o clicado via JavaScript!")
                                return True
                            
                            # M√©todo 2: Fallback para clique direto
                            logger.info("üîÑ V2.0: Tentando clique direto no bot√£o...")
                            botao_confirmar = await page.query_selector('input[type="submit"][value="Confirmar"]')
                            if not botao_confirmar:
                                botao_confirmar = await page.query_selector('input[type="submit"]')
                            if not botao_confirmar:
                                botao_confirmar = await page.query_selector('button[type="submit"]')
                            if not botao_confirmar:
                                botao_confirmar = await page.query_selector('input[value*="Confirmar"]')
                            if not botao_confirmar:
                                botao_confirmar = await page.query_selector('input[value*="OK"]')
                            
                            if botao_confirmar:
                                await botao_confirmar.click(timeout=5000)
                                logger.info("‚úÖ V2.0: Bot√£o de confirma√ß√£o clicado diretamente!")
                                return True
                            else:
                                logger.warning("‚ö†Ô∏è V2.0: Bot√£o de confirma√ß√£o n√£o encontrado")
                                return False
                        except Exception as e:
                            logger.error(f"‚ùå V2.0: Erro ao clicar no bot√£o: {e}")
                            return False
                    else:
                        logger.warning("‚ö†Ô∏è Campo de entrada do CAPTCHA n√£o encontrado")
                except Exception as e:
                    logger.error(f"‚ùå Erro ao inserir texto no campo: {e}")
            else:
                logger.warning(f"‚ö†Ô∏è Sistema V2.0 falhou: confian√ßa {resultado_v2.get('confianca', 0):.2f}, 6+chars: {resultado_v2.get('tem_6_chars', False)}")
            
            # üîÑ FALLBACK 1: Sistema V2.0 j√° processou acima - sem necessidade de fallbacks adicionais
            logger.info("üîÑ Sistema V2.0 j√° processou acima - sem necessidade de fallbacks adicionais")
            
            # Se chegou at√© aqui sem sucesso, o V2.0 j√° esgotou todas as possibilidades
            logger.warning("‚ö†Ô∏è Sistema V2.0 n√£o conseguiu resolver o CAPTCHA")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Erro na resolu√ß√£o CAPTCHA: {e}")
            return False
        finally:
            # Limpar arquivo tempor√°rio
            try:
                import os
                if 'caminho_temp' in locals():
                    os.unlink(caminho_temp)
            except:
                pass
    
    async def executar_downloads_automaticos(self):
        """Executa downloads autom√°ticos de 2023 at√© agora com controle de fluxo inteligente"""
        try:
            # üïí Marcar in√≠cio da execu√ß√£o
            self.tempo_inicio = datetime.now()
            
            # Definir per√≠odo: 01/01/2023 at√© hoje
            data_inicio = datetime(2023, 1, 1)
            data_fim = datetime.now()
            
            logger.info("üéØ INICIANDO DOWNLOADS AUTOM√ÅTICOS DE LICITA√á√ïES")
            logger.info("=" * 60)
            logger.info(f"üìÖ Per√≠odo: {data_inicio.strftime('%d/%m/%Y')} at√© {data_fim.strftime('%d/%m/%Y')}")
            logger.info(f"üïí In√≠cio: {self.tempo_inicio.strftime('%d/%m/%Y %H:%M:%S')}")
            
            # Gerar per√≠odos quinzenais
            periodos = self.gerar_periodos_quinzenais(data_inicio, data_fim)
            logger.info(f"üìä Total de per√≠odos a processar: {len(periodos)}")
            
            # Inicializar progresso se n√£o existir
            if not hasattr(self, 'progresso') or self.progresso is None:
                self.progresso = {
                    "downloads_sucesso": [],
                    "total_downloads_realizados": 0,
                    "inicio_execucao": self.tempo_inicio.isoformat()
                }
            
            # Inicializar navegador
            if not await self.inicializar_navegador():
                logger.error("‚ùå Falha ao inicializar navegador")
                return
            
            total_downloads = 0
            
            try:
                for i, periodo in enumerate(periodos, 1):
                    logger.info(f"üîÑ PROCESSANDO PER√çODO {i}/{len(periodos)}: {periodo['inicio']} a {periodo['fim']}")
                    logger.info("=" * 80)
                    
                    # Navegar para per√≠odo
                    if await self.navegar_para_periodo(periodo):
                        # Processar licita√ß√µes do per√≠odo
                        downloads_periodo = await self.processar_licitacoes_periodo(periodo)
                        total_downloads += downloads_periodo
                        
                        # üìä RELAT√ìRIO DO PER√çODO
                        logger.info("=" * 80)
                        logger.info(f"‚úÖ PER√çODO {i}/{len(periodos)} CONCLU√çDO!")
                        logger.info(f"üìÖ Per√≠odo: {periodo['inicio']} a {periodo['fim']}")
                        logger.info(f"üì• Downloads neste per√≠odo: {downloads_periodo}")
                        logger.info(f"üìä Total acumulado: {total_downloads}")
                        
                        # Atualizar estat√≠sticas de progresso
                        if hasattr(self, 'progresso') and self.progresso is not None:
                            self.progresso["downloads_realizados"] = total_downloads
                            self.progresso["ultimo_periodo_processado"] = f"{periodo['inicio']} a {periodo['fim']}"
                            self.progresso["periodo_atual"] = f"{i}/{len(periodos)}"
                            self.progresso["percentual_concluido"] = round((i / len(periodos)) * 100, 2)
                            self.salvar_progresso()
                        
                        # üéØ DECIS√ÉO DE FLUXO
                        if downloads_periodo > 0:
                            logger.info(f"üéâ Per√≠odo produtivo! {downloads_periodo} downloads realizados")
                        else:
                            logger.info("üì≠ Per√≠odo sem downloads (sem licita√ß√µes ou todas falharam)")
                        
                        logger.info("=" * 80)
                        
                        # Verificar se deve continuar para pr√≥ximo per√≠odo
                        if i < len(periodos):
                            logger.info(f"‚û°Ô∏è AVAN√áANDO PARA PR√ìXIMO PER√çODO ({i+1}/{len(periodos)})...")
                            logger.info(f"üìÖ Pr√≥ximo per√≠odo: {periodos[i]['inicio']} a {periodos[i]['fim']}")
                        else:
                            logger.info("üèÅ TODOS OS PER√çODOS PROCESSADOS!")
                            
                    else:
                        logger.warning(f"‚ö†Ô∏è Falha ao navegar para per√≠odo {i}: {periodo['inicio']} a {periodo['fim']}")
                        logger.info("üîÑ Continuando para pr√≥ximo per√≠odo...")
                    
                    # Pausa entre per√≠odos para evitar sobrecarga
                    if i < len(periodos):  # N√£o fazer pausa no √∫ltimo per√≠odo
                        pausa = random.uniform(3, 6)
                        logger.info(f"‚è∏Ô∏è Pausa de {pausa:.1f}s antes do pr√≥ximo per√≠odo...")
                        await asyncio.sleep(pausa)
                
                # üéâ RELAT√ìRIO FINAL COMPLETO
                logger.info("=" * 80)
                logger.info("üéâ DOWNLOADS AUTOM√ÅTICOS CONCLU√çDOS!")
                logger.info("=" * 80)
                logger.info(f"üìä ESTAT√çSTICAS FINAIS:")
                logger.info(f"   ‚Ä¢ Total de per√≠odos processados: {len(periodos)}")
                logger.info(f"   ‚Ä¢ Total de downloads realizados: {total_downloads}")
                
                # Relat√≥rio detalhado dos downloads
                if hasattr(self, 'progresso') and self.progresso is not None and "downloads_sucesso" in self.progresso:
                    sucessos = self.progresso["downloads_sucesso"]
                    logger.info(f"   ‚Ä¢ Downloads bem-sucedidos registrados: {len(sucessos)}")
                    
                    if sucessos:
                        logger.info("ÔøΩ ARQUIVOS BAIXADOS:")
                        for i, download in enumerate(sucessos[-5:], 1):  # Mostrar √∫ltimos 5
                            logger.info(f"   {i}. {download['arquivo']} ({download['timestamp']})")
                        
                        if len(sucessos) > 5:
                            logger.info(f"   ... e mais {len(sucessos) - 5} arquivos")
                
                tempo_fim = datetime.now()
                if hasattr(self, 'tempo_inicio'):
                    duracao = tempo_fim - self.tempo_inicio
                    logger.info(f"‚è±Ô∏è Tempo total de execu√ß√£o: {duracao}")
                
                logger.info("=" * 80)
                logger.info("üîÑ PR√ìXIMA EXECU√á√ÉO:")
                logger.info("   ‚Ä¢ O sistema sempre processa todos os per√≠odos do zero")
                logger.info("   ‚Ä¢ Execute novamente para buscar novas licita√ß√µes")
                logger.info("   ‚Ä¢ Licita√ß√µes j√° baixadas ser√£o detectadas automaticamente")
                logger.info("=" * 80)
                
            finally:
                # Fechar contexto persistente
                if hasattr(self, 'context') and self.context:
                    await self.context.close()
                if hasattr(self, 'playwright'):
                    await self.playwright.stop()
            
        except Exception as e:
            logger.error(f"‚ùå Erro durante execu√ß√£o autom√°tica: {e}")
    
    async def confirmar_captcha_sucesso_para_ml(self):
        """Confirma CAPTCHA como sucesso para treinamento ML ap√≥s download confirmado"""
        try:
            if hasattr(self, 'ultimo_captcha_resolvido') and self.ultimo_captcha_resolvido:
                captcha_data = self.ultimo_captcha_resolvido
                
                # Salvar o CAPTCHA como sucesso para treinamento ML
                if hasattr(self, 'resolver_v2') and self.resolver_v2:
                    sucesso = self.resolver_v2.salvar_captcha_como_sucesso(
                        captcha_data['img'],
                        captcha_data['texto'],
                        captcha_data['timestamp']
                    )
                    
                    if sucesso:
                        logger.info(f"üéØ CAPTCHA '{captcha_data['texto']}' CONFIRMADO PARA TREINAMENTO ML!")
                        logger.info(f"üéØ M√©todo: {captcha_data['metodo']}, Confian√ßa: {captcha_data['confianca']:.2f}")
                    else:
                        logger.warning("‚ö†Ô∏è Erro ao salvar CAPTCHA como sucesso")
                
                # Limpar dados do √∫ltimo CAPTCHA
                self.ultimo_captcha_resolvido = None
            else:
                logger.debug("üìù Nenhum CAPTCHA resolvido para confirmar")
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao confirmar CAPTCHA para ML: {e}")

async def main():
    """Fun√ß√£o principal"""
    logger.info("üöÄ SISTEMA DE DOWNLOAD AUTOM√ÅTICO DE LICITA√á√ïES")
    logger.info("=" * 60)
    
    downloader = ComprasNetDownloadAutomatico()
    await downloader.executar_downloads_automaticos()

if __name__ == "__main__":
    asyncio.run(main())
